{
  "session_id": "1a87466e-69e9-4a7f-a726-44e16fa446ff",
  "job": "data_scientist.txt",
  "candidate_id": "1a295448-771c-48ab-8ff3-20cc230b5ea8",
  "questions": [
    {
      "id": "1",
      "text": "Walk me through training, validation and deployment steps you would use for a production ML pipeline in Data.",
      "metadata": {
        "source": "mock"
      }
    },
    {
      "id": "2",
      "text": "Walk me through training, validation and deployment steps you would use for a production ML pipeline in Scientist.",
      "metadata": {
        "source": "mock"
      }
    },
    {
      "id": "3",
      "text": "How would you optimize inference performance (latency and throughput) for models serving We traffic?",
      "metadata": {
        "source": "mock"
      }
    },
    {
      "id": "4",
      "text": "Explain the model architecture you would choose for scientist and why. Discuss tradeoffs for latency vs accuracy.",
      "metadata": {
        "source": "mock"
      }
    },
    {
      "id": "5",
      "text": "How would you optimize inference performance (latency and throughput) for models serving experienced traffic?",
      "metadata": {
        "source": "mock"
      }
    }
  ],
  "responses": [],
  "current_index": 0,
  "started_at": 1764408617.789532
}